{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - Lab Week 6 </h3>\n",
    "<h1 align='center'> Converting Categorical Features using DictVectorizer\n",
    " </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In realistic datasets, it is common to see extra values for certain categorical features in test data which are not present in training data. `pandas.get_dummies()` function cannot directly handle these cases. However, `sklearn`'s `DictVectorizer` is the perfect tool to perform categorical feature extraction.\n",
    "\n",
    "The idea is: \n",
    "1. As a transformer, when `fit` on training data, `DictVectorizer` memorizes the universe of all possible values for each categorical features together with the mapping from each value to a unique column number in transformed feature matrix. \n",
    "2. In test time, when seeing a value which is in the universe known to `DictVectorizer` at training time, the vectorizer will look up that `value -> column ID` mapping and find the corresponding column number for this values; **when seeing an unknown value, it will simply ignore it.**\n",
    "\n",
    "All these bookkeeping is done painlessly by sklean. All you need to do is call `DictVectorizer.fit()` on your training data and `DictVectorizer.transform()` on your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Read the competition overview at https://www.kaggle.com/c/home-credit-default-risk#description.\n",
    "We are trying to predict whether each credit applicant is going to have payment difficulty or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T23:24:38.888755Z",
     "start_time": "2019-07-26T23:24:35.268390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 122)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "\n",
    "filename = 'data/application_train.csv'\n",
    "train_df = pd.read_csv(filename)\n",
    "train_df = train_df.sample(5000) # the original dataset is pretty huge, so we just randomly sample 5k out of it\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T23:21:44.878910Z",
     "start_time": "2019-07-26T23:21:44.827188Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43349</th>\n",
       "      <td>150183</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>199080.0</td>\n",
       "      <td>6381.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230313</th>\n",
       "      <td>366773</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>528633.0</td>\n",
       "      <td>20263.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27966</th>\n",
       "      <td>132513</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>385164.0</td>\n",
       "      <td>17095.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67948</th>\n",
       "      <td>178796</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>808650.0</td>\n",
       "      <td>26086.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233411</th>\n",
       "      <td>370353</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>29335.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "43349       150183       0         Cash loans           M            Y   \n",
       "230313      366773       0         Cash loans           F            N   \n",
       "27966       132513       0         Cash loans           F            Y   \n",
       "67948       178796       0         Cash loans           M            N   \n",
       "233411      370353       0         Cash loans           F            N   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "43349                Y             0           94500.0    199080.0   \n",
       "230313               Y             0          108000.0    528633.0   \n",
       "27966                Y             0           54000.0    385164.0   \n",
       "67948                N             0           72000.0    808650.0   \n",
       "233411               N             0          135000.0    490495.5   \n",
       "\n",
       "        AMT_ANNUITY             ...              FLAG_DOCUMENT_18  \\\n",
       "43349        6381.0             ...                             0   \n",
       "230313      20263.5             ...                             0   \n",
       "27966       17095.5             ...                             0   \n",
       "67948       26086.5             ...                             0   \n",
       "233411      29335.5             ...                             0   \n",
       "\n",
       "       FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "43349                 0                0                0   \n",
       "230313                0                0                0   \n",
       "27966                 0                0                0   \n",
       "67948                 0                0                0   \n",
       "233411                0                0                0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "43349                         0.0                       0.0   \n",
       "230313                        NaN                       NaN   \n",
       "27966                         0.0                       0.0   \n",
       "67948                         0.0                       0.0   \n",
       "233411                        0.0                       0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "43349                          0.0                        0.0   \n",
       "230313                         NaN                        NaN   \n",
       "27966                          0.0                        1.0   \n",
       "67948                          0.0                        0.0   \n",
       "233411                         0.0                        4.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "43349                         0.0                         2.0  \n",
       "230313                        NaN                         NaN  \n",
       "27966                         0.0                         3.0  \n",
       "67948                         0.0                         0.0  \n",
       "233411                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check the number of object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T23:57:24.959746Z",
     "start_time": "2019-07-26T23:57:24.939024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE            object\n",
       "CODE_GENDER                   object\n",
       "FLAG_OWN_CAR                  object\n",
       "FLAG_OWN_REALTY               object\n",
       "NAME_TYPE_SUITE               object\n",
       "NAME_INCOME_TYPE              object\n",
       "NAME_EDUCATION_TYPE           object\n",
       "NAME_FAMILY_STATUS            object\n",
       "NAME_HOUSING_TYPE             object\n",
       "OCCUPATION_TYPE               object\n",
       "WEEKDAY_APPR_PROCESS_START    object\n",
       "ORGANIZATION_TYPE             object\n",
       "FONDKAPREMONT_MODE            object\n",
       "HOUSETYPE_MODE                object\n",
       "WALLSMATERIAL_MODE            object\n",
       "EMERGENCYSTATE_MODE           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.select_dtypes(include=['category','object']).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:56:43.133080Z",
     "start_time": "2019-07-27T02:56:43.128167Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_df['TARGET'].values\n",
    "X = train_df.drop(['TARGET'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:56:53.049310Z",
     "start_time": "2019-07-27T02:56:53.046154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 121)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to prepare a list with dict-like objects for the `DictVectorizer`, check [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html).\n",
    "\n",
    "`[{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]`\n",
    "\n",
    "First, let's see the usage of method: `.iterrows()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:09:21.394269Z",
     "start_time": "2019-07-27T03:09:21.379293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   int  float\n",
      "0    1    1.5\n",
      "1    3    5.0\n",
      "{'int': 1.0, 'float': 1.5}\n",
      "{'int': 3.0, 'float': 5.0}\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame([[1, 1.5],[3,5]], columns=['int', 'float'])\n",
    "print(df_test)\n",
    "\n",
    "for a, b in df_test.iterrows():\n",
    "    print(dict(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:10:12.832966Z",
     "start_time": "2019-07-27T03:10:09.546720Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [dict(row) for _, row in X.iterrows()] #_ stands for index, which we don't care"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:11:01.974375Z",
     "start_time": "2019-07-27T03:11:01.967477Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val, y_train, y_val = train_test_split(data, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:11:02.884059Z",
     "start_time": "2019-07-27T03:11:02.880681Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SK_ID_CURR': 384265, 'NAME_CONTRACT_TYPE': 'Cash loans', 'CODE_GENDER': 'F', 'FLAG_OWN_CAR': 'N', 'FLAG_OWN_REALTY': 'N', 'CNT_CHILDREN': 1, 'AMT_INCOME_TOTAL': 135000.0, 'AMT_CREDIT': 675000.0, 'AMT_ANNUITY': 32602.5, 'AMT_GOODS_PRICE': 675000.0, 'NAME_TYPE_SUITE': 'Unaccompanied', 'NAME_INCOME_TYPE': 'Working', 'NAME_EDUCATION_TYPE': 'Secondary / secondary special', 'NAME_FAMILY_STATUS': 'Married', 'NAME_HOUSING_TYPE': 'House / apartment', 'REGION_POPULATION_RELATIVE': 0.009334, 'DAYS_BIRTH': -13440, 'DAYS_EMPLOYED': -6595, 'DAYS_REGISTRATION': -7535.0, 'DAYS_ID_PUBLISH': -1615, 'OWN_CAR_AGE': nan, 'FLAG_MOBIL': 1, 'FLAG_EMP_PHONE': 1, 'FLAG_WORK_PHONE': 1, 'FLAG_CONT_MOBILE': 1, 'FLAG_PHONE': 1, 'FLAG_EMAIL': 0, 'OCCUPATION_TYPE': 'High skill tech staff', 'CNT_FAM_MEMBERS': 3.0, 'REGION_RATING_CLIENT': 2, 'REGION_RATING_CLIENT_W_CITY': 2, 'WEEKDAY_APPR_PROCESS_START': 'WEDNESDAY', 'HOUR_APPR_PROCESS_START': 17, 'REG_REGION_NOT_LIVE_REGION': 0, 'REG_REGION_NOT_WORK_REGION': 0, 'LIVE_REGION_NOT_WORK_REGION': 0, 'REG_CITY_NOT_LIVE_CITY': 0, 'REG_CITY_NOT_WORK_CITY': 0, 'LIVE_CITY_NOT_WORK_CITY': 0, 'ORGANIZATION_TYPE': 'Agriculture', 'EXT_SOURCE_1': 0.4162410031511667, 'EXT_SOURCE_2': 0.6269373399883886, 'EXT_SOURCE_3': 0.28812959991785075, 'APARTMENTS_AVG': nan, 'BASEMENTAREA_AVG': nan, 'YEARS_BEGINEXPLUATATION_AVG': 0.9801, 'YEARS_BUILD_AVG': nan, 'COMMONAREA_AVG': nan, 'ELEVATORS_AVG': nan, 'ENTRANCES_AVG': nan, 'FLOORSMAX_AVG': nan, 'FLOORSMIN_AVG': nan, 'LANDAREA_AVG': nan, 'LIVINGAPARTMENTS_AVG': nan, 'LIVINGAREA_AVG': nan, 'NONLIVINGAPARTMENTS_AVG': nan, 'NONLIVINGAREA_AVG': nan, 'APARTMENTS_MODE': nan, 'BASEMENTAREA_MODE': nan, 'YEARS_BEGINEXPLUATATION_MODE': 0.9801, 'YEARS_BUILD_MODE': nan, 'COMMONAREA_MODE': nan, 'ELEVATORS_MODE': nan, 'ENTRANCES_MODE': nan, 'FLOORSMAX_MODE': nan, 'FLOORSMIN_MODE': nan, 'LANDAREA_MODE': nan, 'LIVINGAPARTMENTS_MODE': nan, 'LIVINGAREA_MODE': nan, 'NONLIVINGAPARTMENTS_MODE': nan, 'NONLIVINGAREA_MODE': nan, 'APARTMENTS_MEDI': nan, 'BASEMENTAREA_MEDI': nan, 'YEARS_BEGINEXPLUATATION_MEDI': 0.9801, 'YEARS_BUILD_MEDI': nan, 'COMMONAREA_MEDI': nan, 'ELEVATORS_MEDI': nan, 'ENTRANCES_MEDI': nan, 'FLOORSMAX_MEDI': nan, 'FLOORSMIN_MEDI': nan, 'LANDAREA_MEDI': nan, 'LIVINGAPARTMENTS_MEDI': nan, 'LIVINGAREA_MEDI': nan, 'NONLIVINGAPARTMENTS_MEDI': nan, 'NONLIVINGAREA_MEDI': nan, 'FONDKAPREMONT_MODE': nan, 'HOUSETYPE_MODE': nan, 'TOTALAREA_MODE': 0.0786, 'WALLSMATERIAL_MODE': nan, 'EMERGENCYSTATE_MODE': 'No', 'OBS_30_CNT_SOCIAL_CIRCLE': 2.0, 'DEF_30_CNT_SOCIAL_CIRCLE': 0.0, 'OBS_60_CNT_SOCIAL_CIRCLE': 2.0, 'DEF_60_CNT_SOCIAL_CIRCLE': 0.0, 'DAYS_LAST_PHONE_CHANGE': -2411.0, 'FLAG_DOCUMENT_2': 0, 'FLAG_DOCUMENT_3': 1, 'FLAG_DOCUMENT_4': 0, 'FLAG_DOCUMENT_5': 0, 'FLAG_DOCUMENT_6': 0, 'FLAG_DOCUMENT_7': 0, 'FLAG_DOCUMENT_8': 0, 'FLAG_DOCUMENT_9': 0, 'FLAG_DOCUMENT_10': 0, 'FLAG_DOCUMENT_11': 0, 'FLAG_DOCUMENT_12': 0, 'FLAG_DOCUMENT_13': 0, 'FLAG_DOCUMENT_14': 0, 'FLAG_DOCUMENT_15': 0, 'FLAG_DOCUMENT_16': 0, 'FLAG_DOCUMENT_17': 0, 'FLAG_DOCUMENT_18': 0, 'FLAG_DOCUMENT_19': 0, 'FLAG_DOCUMENT_20': 0, 'FLAG_DOCUMENT_21': 0, 'AMT_REQ_CREDIT_BUREAU_HOUR': 0.0, 'AMT_REQ_CREDIT_BUREAU_DAY': 0.0, 'AMT_REQ_CREDIT_BUREAU_WEEK': 0.0, 'AMT_REQ_CREDIT_BUREAU_MON': 0.0, 'AMT_REQ_CREDIT_BUREAU_QRT': 0.0, 'AMT_REQ_CREDIT_BUREAU_YEAR': 2.0}\n"
     ]
    }
   ],
   "source": [
    "print(data_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categoricals to one-hot-encoding\n",
    "When your data comes as a list of dictionaries, Scikit-Learn's DictVectorizer will do one-hot encoding for you.[Reference](https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:16:40.750293Z",
     "start_time": "2019-07-27T03:16:40.405588Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "      \n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(data_train) # fit the DictVectorizer on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:18:26.671871Z",
     "start_time": "2019-07-27T03:18:26.669062Z"
    }
   },
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:18:29.098500Z",
     "start_time": "2019-07-27T03:18:29.095453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features after conversion: 245\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of features after conversion: {len( features)}') # any feature name looking like `FEATURE=VAL` is a result of categorical feature conversion)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform the categoricals in test dataset by using the vectorizer fitted from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:19:33.103341Z",
     "start_time": "2019-07-27T03:19:33.100124Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = [{'EMERGENCYSTATE_MODE' : 'UNK', 'AMT_ANNUITY': 1000, 'APARTMENTS_AVG': 250}] # `UNK` is an unseen value for `EMERGENCYSTATE_MODE`\n",
    "X_test = vectorizer.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:23:45.429285Z",
     "start_time": "2019-07-27T03:23:45.425125Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 245)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T03:23:18.386997Z",
     "start_time": "2019-07-27T03:23:18.370172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY: 1000.0\n",
      "APARTMENTS_AVG: 250.0\n"
     ]
    }
   ],
   "source": [
    "for (i, feature) in enumerate(features):\n",
    "    if X_test[0, i]:\n",
    "        print(f'{feature}: {X_test[0, i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **when DictVectorizer() seeing an unknown value, it will simply ignore it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: \n",
    "\n",
    "Use Pycharm to finish the following:\n",
    "\n",
    "1. Do `train_val_split` as above.\n",
    "2. Do proper feature extraction by fitting `DictVectorizer` on your training data and use the fitted vectorizer to transform you validation data.\n",
    "3. Fit a `BaggingClassifier` using `DecisionTree` as base_estimator on your training data:\n",
    "   - Use all default values. \n",
    "   - Reference: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "4. Report the `oob_score` for each of your fitted base classifier and the performance on your **test data**.\n",
    "5. (Optional) Compare the validation performance of your bagging model with that of a standard `DecisionTree` model. \n",
    "\n",
    "Note: the original dataset is quite large. You can randomly sample a good amount of rows from it for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
