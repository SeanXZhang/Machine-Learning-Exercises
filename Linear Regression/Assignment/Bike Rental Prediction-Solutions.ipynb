{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - Assignment Week 1 </h3>\n",
    "<h1 align='center'> Bike Rental Prediction </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Background</h2>\n",
    "\n",
    "Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.\n",
    "\n",
    "The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.\n",
    "\n",
    "You are provided daily rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each day covered by the test set, using only information available prior to the rental period.\n",
    "\n",
    "> We will be using the `train.csv` for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Description</h2>\n",
    "\n",
    "<b>Features:</b>\n",
    "\n",
    "- datetime - hourly date + timestamp\n",
    "- season -  1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather  \n",
    "  - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "  - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "  - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "  - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "\n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "\n",
    "<b>Features should not be used:</b>\n",
    "\n",
    "- casual - number of non-registered user rentals initiated (Not Provided in Test Data)\n",
    "- registered - number of registered user rentals initiated (Not Provided in Test Data)\n",
    "\n",
    "<b>Target Value:</b>\n",
    "\n",
    "- count - number of total rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ 1: Explore the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Import two libraries: \n",
    "  - 'pandas', \n",
    "  - 'numpy'\n",
    "  - 'matplotlib'(used for data visualization)\n",
    "\n",
    "- Step 2: Load the training data `train.csv` into a Dataframe named 'data'.\n",
    "\n",
    "- Step 3: Explore the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ 2: Get Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 1: Drop the `casual` and `registered` columns.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['casual' 'registered'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d2babd02e1e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Step 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'casual'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'registered'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2562\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3744\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['casual' 'registered'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "data = data.drop(columns=['casual', 'registered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['casual' 'registered'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e60a0c118367>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'casual'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'registered'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2562\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3744\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['casual' 'registered'] not contained in axis"
     ]
    }
   ],
   "source": [
    "data.drop(columns=['casual', 'registered'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 2: Convert the 'datetime' feature to Year, Month, and Hour</b>\n",
    "  - Date attribute cannot be taken as a numerical feature in a regression analysis. We need to convert the 'datetime' column into four columns: Year, Month, and Hour.\n",
    "  - example: 2011-01-01 02:00:00 \n",
    "    - Year: 2011, \n",
    "    - Month: 1,\n",
    "    - Hour: 2\n",
    "\n",
    " - After add those three columns, drop the 'datetime' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "from dateutil import parser\n",
    "\n",
    "data['year'] = data['datetime'].map(lambda x : parser.parse(x).year)\n",
    "data['month'] = data['datetime'].map(lambda x : parser.parse(x).month)\n",
    "data['hour'] = data['datetime'].map(lambda x : parser.parse(x).hour)\n",
    "data=data.drop(columns=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 3: Get a list of all categorical variables</b>\n",
    "\n",
    "  - Use data.columns to check what columns in our `data` now.\n",
    "\n",
    "  - Now that in our data we have both numerical features and categorical features, we need to convert categorical features to Numerical features.\n",
    "\n",
    "  - Some of the features are already 0,1 (binary) style, such as `holiday`. So we don't need to convert them to dummy variables.\n",
    "\n",
    "  - In step 3, please identify Categorical features (those need to be converted) in the data and save all their column names to a list.\n",
    "    - Example: `categorical_features = ['season', ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
       "       'humidity', 'windspeed', 'count', 'year', 'month', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['season', 'weather', 'year', 'month', 'hour']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 4: Converting categorical features to numerical </b>\n",
    "  - Convert these categorical_features to dummies\n",
    "  - Hint:\n",
    "    - `data = pd.get_dummies(data,columns=categorical_features,drop_first=True)`\n",
    "    - Guess what 'drop_first=True' means here and why we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday  workingday  temp   atemp  humidity  windspeed  count  season_2  \\\n",
       "0        0           0  9.84  14.395        81        0.0     16         0   \n",
       "1        0           0  9.02  13.635        80        0.0     40         0   \n",
       "2        0           0  9.02  13.635        80        0.0     32         0   \n",
       "3        0           0  9.84  14.395        75        0.0     13         0   \n",
       "4        0           0  9.84  14.395        75        0.0      1         0   \n",
       "\n",
       "   season_3  season_4   ...     hour_14  hour_15  hour_16  hour_17  hour_18  \\\n",
       "0         0         0   ...           0        0        0        0        0   \n",
       "1         0         0   ...           0        0        0        0        0   \n",
       "2         0         0   ...           0        0        0        0        0   \n",
       "3         0         0   ...           0        0        0        0        0   \n",
       "4         0         0   ...           0        0        0        0        0   \n",
       "\n",
       "   hour_19  hour_20  hour_21  hour_22  hour_23  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4\n",
    "data = pd.get_dummies(data,columns=categorical_features,drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 5: Count how many columns in the Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['holiday', 'workingday', 'temp', 'atemp', 'humidity', 'windspeed',\n",
      "       'count', 'season_2', 'season_3', 'season_4', 'weather_2', 'weather_3',\n",
      "       'weather_4', 'year_2012', 'month_2', 'month_3', 'month_4', 'month_5',\n",
      "       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
      "       'month_12', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6',\n",
      "       'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
      "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
      "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5\n",
    "print(data.columns)\n",
    "len(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ 3: Prepare Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 1</b>\n",
    "\n",
    "  - According to the Data Information, our Target Value is data['count'].\n",
    "  - Input Features should include all other features **except**: data['count'], data['casual'], data['registered']\n",
    "  - So we need to set y = data['count'] and X include other part of the dataframe except those three columns we just mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "y = data['count']\n",
    "X = data.drop(columns=['count'], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 2</b>\n",
    "\n",
    "  - Use the 'train_test_split' function in scikit learn to split X and y into 80% Traning data and 20% Testing Data\n",
    "  \n",
    "  - Hint: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 3</b>\n",
    "\n",
    "  - Perform feature standardization on `X_train` by using sklearn's `StandardScaler`, and use the same standardizer to standardize `X_test`.\n",
    "  - Hint: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ 4: Linear Regression </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 1</b>\n",
    "\n",
    "  - Import the linear_model from scikit learn and mean_squared_error to evaluate the result of the regression model \n",
    "  - Create a Linear Regression model - 'lr' and fit X_train and Y_train to train it.\n",
    "  - Hint: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 2</b>\n",
    "  - Use lr.predict on X_test to get predicted value of y and call mean_squared_error(y_test, y_predict) to get the mean squre error(MSE).\n",
    "  - Call numpy's function to calculate the squre root of MSE(RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "from sklearn.metrics.regression import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_predict = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 10209.796629904886, rmse: 101.04353828872426\n"
     ]
    }
   ],
   "source": [
    "print(f'mse: {mse}, rmse: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ Problem 5 (Advanced): Implement gradient descent on linear regression</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 1</b>\n",
    "\n",
    "  - Under the hood, Scikit-learn does not use gradient descent to fit LinearRegression; rather, it uses an approximation to the exact analytical solution we have seen using calculus.\n",
    "\n",
    "  - Therefore, it is a chanllenge for you to implement gradient descent on linear regession.\n",
    "\n",
    "  - In this step, we initialize a weight/coefficient vector $\\theta$ randomly. This vector should have the same dimensionality of the features in the training data, i.e., one coefficient for one single feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80046673, 0.2089502 , 0.29974872, 0.9285824 , 0.85001824,\n",
       "       0.70082229, 0.8050946 , 0.15789947, 0.22658672, 0.004763  ,\n",
       "       0.92264301, 0.05198593, 0.17942169, 0.516006  , 0.9547122 ,\n",
       "       0.49544901, 0.25240129, 0.66069636, 0.51520871, 0.71340889,\n",
       "       0.56663412, 0.61650365, 0.02810156, 0.99608188, 0.44603582,\n",
       "       0.27501063, 0.73062522, 0.09268111, 0.78600851, 0.66440595,\n",
       "       0.84604077, 0.41106634, 0.4735135 , 0.49315111, 0.51659527,\n",
       "       0.3752307 , 0.37260652, 0.98644223, 0.60586243, 0.99009374,\n",
       "       0.87711671, 0.30263682, 0.67149267, 0.53808458, 0.65896569,\n",
       "       0.21693684, 0.89666578])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1\n",
    "import numpy.random\n",
    "def initialize_theta(dim):\n",
    "    # TODO: randomly initialize coefficient to be a dim-sized 1D vector\n",
    "    \n",
    "    theta = np.random.random(dim)\n",
    "    return theta\n",
    "initialize_theta(len(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 2</b>\n",
    "\n",
    "  - Calculate the gradient of the linear regresion function $h_\\theta(x)$ against each $\\theta_i$. Hint: we have talked about this gradient in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: implement this function\n",
    "import numpy as np\n",
    "\n",
    "def prediction(X, current_theta):\n",
    "    # TODO: compute the current estimation of the output, H, given the current_theta and X\n",
    "    # X.shape: m*(p+1)\n",
    "    # current_theta.shape: (p+1)*1\n",
    "    \n",
    "    return np.dot(X, current_theta) # H.shape: m*1\n",
    "\n",
    "#     or, you can use non-matrix calculation:\n",
    "#     H = []\n",
    "#     m = X.shape[0]\n",
    "#     for i in range(m):\n",
    "#         H.append(np.dot(X[i], current_theta))\n",
    "    \n",
    "#     return np.array(H)\n",
    "\n",
    "def loss(X, y, current_theta):\n",
    "    H = prediction(X, current_theta) # H.shape: m*1\n",
    "    # TODO: compute loss function J, given H, and y\n",
    "    return np.sum((H - y)**2)/(2 * X.shape[0]) # a scaler\n",
    "\n",
    "#     or, you can use non-matrix calculation\n",
    "#     loss = 0\n",
    "#     m = X.shape[0]\n",
    "#     for i in range(m):\n",
    "#         loss += (H[i] - y[i])**2\n",
    "#     return loss / (2 * m)\n",
    "\n",
    "def loss_gradient(X, y, current_theta):\n",
    "    # TODO: implement the loss gradient\n",
    "    # compute the current estimation of the output, H, given the current_theta and X\n",
    "    # compute loss function J, given H, and y\n",
    "    # compute gradient of this loss function against current_theta\n",
    "    H = prediction(X, current_theta) # H.shape: m*1\n",
    "    \n",
    "    return np.dot(X.T, (H - y)) / X.shape[0]  # shape: (p+1)*1\n",
    "\n",
    "#     or, you can use non-matrix calculation\n",
    "#     # X.shape: m*(p+1), X.T.shape: (p+1)* m\n",
    "#     m = X.shape[0]\n",
    "#     p = X.shape[1] - 1\n",
    "#     gradients = []\n",
    "#     for j in range(p + 1):\n",
    "#         gradient_j = 0\n",
    "#         for i in range(m):\n",
    "#             gradient_j += (H[i] - y[i]) * X[i, j]\n",
    "#         gradients.append(np.sum(gradient_j) / m)\n",
    "    \n",
    "#     return np.array(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 3</b>\n",
    "\n",
    "  - Define a learning rate $\\alpha$, which would be the step size to update each $\\theta_i$, $\\theta_i=\\theta_i - \\alpha \\times loss\\_gradient_i$. Repeatedly updating all $\\theta_i$'s until the loss converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:\n",
    "\n",
    "def update_theta(gradient, current_theta, step_size):\n",
    "    # TODO: implement theta update logic\n",
    "    return current_theta - step_size * gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the skeleton code here for you\n",
    "\n",
    "# convert pandas dataframe into numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_train = np.column_stack([np.ones(X_train.shape[0]), X_train]) # x0=1\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.column_stack([np.ones(X_test.shape[0]), X_test]) # x0=1\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converge after 942 iterations\n"
     ]
    }
   ],
   "source": [
    "precision = 0.001\n",
    "step_size = 0.1 # use your own step_size\n",
    "current_theta = initialize_theta(dim=X_train.shape[1]) # you need to determine the input value to `dim`\n",
    "current_loss = loss(X_train, y_train, current_theta)\n",
    "losses = [current_loss]\n",
    "\n",
    "while len(losses) < 3 or abs(losses[-1] - losses[-2]) > precision: # all some other convergence condition\n",
    "    gradient = loss_gradient(X_train, y_train, current_theta)\n",
    "    current_theta = update_theta(gradient, current_theta, step_size)\n",
    "    \n",
    "    # compute current loss\n",
    "    current_loss = loss(X_train, y_train, current_theta)\n",
    "    losses.append(current_loss)\n",
    "    \n",
    "# once converged, current_theta are therefore the coefficients in the linear regression model  \n",
    "print(f'converge after {len(losses)} iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb3e9358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss against number of iterations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Step 4</b>\n",
    "\n",
    "  - Calculate the RMSE of your trained model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "from sklearn.metrics.regression import r2_score\n",
    "\n",
    "y_pred = np.dot(X_test, np.array(current_theta))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rms = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 10213.063729938096, rmse: 101.04353828872426, r2_score: 0.7005045894548345\n"
     ]
    }
   ],
   "source": [
    "print(f'mse: {mse}, rmse: {rmse}, r2_score: {r2}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
