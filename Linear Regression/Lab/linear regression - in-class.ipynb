{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - In-class Lab Week 1 </h3>\n",
    "<h1 align='center'> Linear Regression </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages Used:\n",
    "\n",
    "- [NumPy](http://www.numpy.org/): a fundamental package for scientific computing with Python.\n",
    "- [seaborn](https://seaborn.pydata.org/): statistical data visualization.\n",
    "- [Bokeh](http://bokeh.pydata.org/en/latest/): a Python interactive visualization library that targets modern web browsers for presentation.\n",
    "- [Matplotlib](https://matplotlib.org/): a Python 2D plotting library.\n",
    "- [Sklearn](http://scikit-learn.org/stable/): Machine Learning tools in Python.\n",
    "- [SciPy](https://www.scipy.org/): a Python-based ecosystem of open-source software for mathematics, science, and engineering.\n",
    "- [JSAnimation](https://github.com/jakevdp/JSAnimation): an HTML/Javascript writer for Matplotlib animations.\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "- [Optimzation](#Optimzation)\n",
    "  - Minimizing a quadratic equation using calculus\n",
    "  - Minimizing a quadratic equation using Gradient Descent\n",
    "- [Linear regression](#Linear-regression)\n",
    "  - Data preparation\n",
    "  - Train linear regressor analytically\n",
    "  - Train linear regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.082531Z",
     "start_time": "2019-06-15T21:31:01.967638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading necessary libraries and setting up plotting libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_regression \n",
    "from scipy import stats \n",
    "from bokeh.models import  WheelZoomTool, ResetTool, PanTool\n",
    "from bokeh.layouts import gridplot\n",
    "from JSAnimation import IPython_display\n",
    "\n",
    "W = 590\n",
    "H = 350\n",
    "bp.output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimzation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ 1. Minimizing a quadratic equation using calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we have a simple quadratic function, $f(x) = x^2 − 6x + 5$, and we want to find the minimum of this function. We can solve this analytically using calculus, by finding the derivate and setting it to zero:\n",
    "\n",
    "$$\\begin{align}\n",
    "f'(x) = 0\\\\\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the quadratic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.087242Z",
     "start_time": "2019-06-15T21:31:03.084831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function and data\n",
    "x = np.linspace(-15,21,100) # evenly 100 spaced numbers over [-15,21].\n",
    "y = x**2-6*x+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 1.1: Calculate the gradient $f'(x)$\n",
    "\n",
    "Since we only have one variable $x$ in function $f(x)$, the gradient is the same as the derivate $f'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.092057Z",
     "start_time": "2019-06-15T21:31:03.088920Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-d32a5d87223d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-d32a5d87223d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    # TODO: you need to implement this function so it returns f'(x)\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "### Define derivative function\n",
    "\n",
    "def f_derivative(x):\n",
    "    # TODO: you need to implement this function so it returns f'(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 1.2: Verify your gradient\n",
    "\n",
    "Find the optimal value of $x$ that minimizes the given equation $f(x)$ by solving the equation $f'(x) = 0$. You can verify if your calculated optimal value $x$ is correct by simply plotting the function $f(x)$, and see whether the function indeed reaches its minimum at your calculated value $x$.\n",
    "\n",
    "The following code snippet plots the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.096824Z",
     "start_time": "2019-06-15T21:31:01.975Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the function\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-3, 10)\n",
    "plt.ylim(-5, 10)\n",
    "plt.plot(3, -4, 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ 2. Minimizing a quadratic equation using Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function is as simple as the quadratic function $f(x) = x^2 − 6x + 5$, we can find the optimal solution to $x$ by solving the equation $f'(x)=0$ analytically. We say these functions have closed-form solutions.\n",
    "\n",
    "However, in the world of machine learning, most of the functions that we want to optimize are high dimensional (with a lot of variables) and very complicated. Therefore, we need a more generic solution that can help us find some optimal (usually only local optimal) solution.\n",
    "\n",
    "Gradient Descent is one of those generic soultions to find the local minimum of a given function - it's an iterative **optimization algorithm** based on the steepest descent. To find the local minimum, you start at a random point, and move into the direction of steepest descent relative to the gradient, i.e. into the direction that goes down (hence, **descent**). \n",
    "\n",
    "In this example, let's suppose we start at $x = 15$. \n",
    "\n",
    "We then calculate the gradient, $f'(x) = 2x - 6$ (this should be your answer to **Practice 1.1** above), at this point is $2 \\times 15 - 6 = 24$. We update our estimation of the optimal $x$ by \n",
    "\n",
    "$$\\begin{align}\n",
    "x'=x-\\alpha f'(x)\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "$\\alpha$ is the **step size** (or called learning rate) of our optimization process, it controls how aggressive we are when updating the value of $x$. It has to be chosen carefully, as a value too small will result in a long computation time, while a value too large will not give you the right result (by overshooting) or even fail to converge.\n",
    "\n",
    "In this example, we'll set the step size to 0.01, which means we'll subtract $24 \\times 0.01$ from 15, which is $14.76$. This is now our new temporary local minimum: We continue this method until we either don't see a change after we subtracted the gradient * step size, or until we've completed a pre-set number of iterations. \n",
    "\n",
    "The algorithm stops when the values between the new and the temporary minimum do not differ by more than 0.001 - if we need more precision, we can decrease this value. According to gradient descent, the local minimum occurs at $3.5$, which is not too far off from the true local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.098534Z",
     "start_time": "2019-06-15T21:31:01.978Z"
    }
   },
   "outputs": [],
   "source": [
    "### Initialization\n",
    "\n",
    "old_min = 0\n",
    "temp_min = 15\n",
    "step_size = 0.001  # small step size\n",
    "precision = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 2.1. Implement updating $x'=x-\\alpha f'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.100153Z",
     "start_time": "2019-06-15T21:31:01.980Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_x(gradient, step_size, current_x):\n",
    "    # TODO: implement the logic of updating x using the given step_size and gradient x'=x-\\alphra * f'(x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 2.2. Implement the iterative gradient descent optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.101455Z",
     "start_time": "2019-06-15T21:31:01.983Z"
    }
   },
   "outputs": [],
   "source": [
    "### Gradient Updates\n",
    "\n",
    "mins = [] # a list to keep track of minimum\n",
    "cost = [] # a list to keep track of cost function\n",
    "\n",
    "while abs(temp_min - old_min) > precision:\n",
    "    old_min = temp_min \n",
    "    gradient = f_derivative(old_min)  # calculate gradient\n",
    "    \n",
    "    # make update to get the newly estimated best x so far\n",
    "    temp_min = update_x(step_size=step_size, gradient=gradient, current_x=old_min) \n",
    "    \n",
    "    cost.append((3-temp_min)**2)      # append squared error to  \n",
    "    mins.append(temp_min)             # append minium to list\n",
    "\n",
    "\n",
    "print(\"Local minimum occurs at {}.\".format(round(temp_min,2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graident update steps\n",
    "\n",
    "We can visualize the gradient descent by plotting all temporary local minima on the curve. As you can see, the improvement decreases over time; at the end, the local minimum barely improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.102893Z",
     "start_time": "2019-06-15T21:31:01.986Z"
    }
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "def animate(i):\n",
    "    x_n = mins[0::10][i]\n",
    "    y_n = x_n**2-6*x_n+5\n",
    "    line.set_data(x_n, y_n)\n",
    "    return line,\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(xlim=(-15, 21), ylim=(-50, 350))\n",
    "ax.plot(x,y, linewidth=4 )\n",
    "line, = ax.plot([], [], \"D\", markersize=12)\n",
    "animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                        frames=len(mins[0::10]), interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the squared distance to local minimum\n",
    "\n",
    "Another important visualization of gradient descent is that there should be a visible improvement over time: In this example, we simply plot the squared distance from the local minima calculated by gradient descent and the true local minimum against the iteration during which it was calculated. As we can see, the distance gets smaller over time, but barely changes in later iterations. This measure of distance is often called the cost or loss, but the implementation differs depending on what function you're trying to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.104119Z",
     "start_time": "2019-06-15T21:31:01.990Z"
    }
   },
   "outputs": [],
   "source": [
    "TOOLS = [WheelZoomTool(), ResetTool(), PanTool()]\n",
    "\n",
    "x_iter, y_distance = (zip(*enumerate(cost)))\n",
    "s1 = bp.figure(width=W, \n",
    "               height=H, \n",
    "               title='Squared distance to true local minimum', \n",
    "               tools=TOOLS,\n",
    "               x_axis_label = 'Iteration',\n",
    "               y_axis_label = 'Distance'\n",
    ")\n",
    "s1.line(x_iter, y_distance, color=\"navy\", alpha=0.5, line_width=3)\n",
    "s1.title.text_font_size = '16pt'\n",
    "s1.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "s1.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "\n",
    "bp.show(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download practice data from [Kaggle's house sale prediction dataset](https://www.kaggle.com/harlfoxem/housesalesprediction#kc_house_data.csv).\n",
    "2. Unzip the zip file and save the CSV.\n",
    "\n",
    "In this practice, we will use some of the features (columns) in this CSV file to predict the `price` column. This is a regression problem, because our target is a continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ 3. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:09.377913Z",
     "start_time": "2019-06-15T21:31:09.303251Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data from csv using pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 3.1. Inspect the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:10.273932Z",
     "start_time": "2019-06-15T21:31:10.271296Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: print out a snippet of the data in the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.107054Z",
     "start_time": "2019-06-15T21:31:01.998Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: sample 10000 rows from df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.107890Z",
     "start_time": "2019-06-15T21:31:02.001Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: print out all column names and their data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choosing a subset of columns as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.109004Z",
     "start_time": "2019-06-15T21:31:02.003Z"
    }
   },
   "outputs": [],
   "source": [
    "# take a subset of the columns for practice.\n",
    "df_sub = df[['price', 'bedrooms', 'bathrooms', 'sqft_living', 'floors']]\n",
    "print(df_sub.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will predict the `price` column, we need to separate it from the \"feature\" columns. Conventionally, the data we use (i.e., the matrix whose rows are the training samples and whose columns are the features) are represented by variable $X$ (capitalized as this is a matrix) and the targets are represented by variable $y$ (in lowercase as this is a vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.109977Z",
     "start_time": "2019-06-15T21:31:02.005Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df_sub['price']\n",
    "X = df_sub.drop(columns=['price'])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the split above, the four columns **\"bedrooms\", \"bathrooms\", \"sqft_living\", and \"floors\"** are so-called \"features\", and **\"price\"** is our targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Adding the dummy variable $x_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As introduced in class, to simplify calculation, we usually add a dummy variable $x_0=1$ in addition to all the existing columns in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.110827Z",
     "start_time": "2019-06-15T21:31:02.008Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.column_stack([np.ones(X.shape[0]), X]) # x0=1\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.111956Z",
     "start_time": "2019-06-15T21:31:02.010Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split of the dataset\n",
    "\n",
    "To validate the quality of our model, we need to train the linear regressor on a set of data (usually called training data) and evaluate on a different set (usually called validation or test set). \n",
    "\n",
    "The convention is to separate the data set into 80% training and 20% validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.114267Z",
     "start_time": "2019-06-15T21:31:02.013Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.115612Z",
     "start_time": "2019-06-15T21:31:02.015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the splitting result by printing out the shapes of our training/testing data and targets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ 4. Train linear regressor analytically (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have more than one features (the columns) in our training data $X$, this is still a linear regression problem, simply with more variables. Therefore, as mentioned in the class, there is still a **closed-formed** solution to find the optimal values of our coefficients $\\theta^*$ using the formula below.\n",
    "\n",
    "$$\\begin{align}\n",
    "H = X^T\\theta \\\\\n",
    "\\theta^* = (X^TX)^{-1}X^TY \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "$\\theta^*$ is the set of coefficients associated with each of our features **\"bedrooms\", \"bathrooms\", \"sqft_living\", and \"floors\"** which yield the lowest mean squared error on our training data $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Practice 4.1. Calculate $\\theta^*$ using the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.116844Z",
     "start_time": "2019-06-15T21:31:02.019Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.118026Z",
     "start_time": "2019-06-15T21:31:02.022Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: calculate the optimal thetas\n",
    "from numpy.linalg import inv\n",
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.119218Z",
     "start_time": "2019-06-15T21:31:02.025Z"
    }
   },
   "outputs": [],
   "source": [
    "# print out your coefficients\n",
    "print(f'coefficients: {theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train linear regressor using Sklearn\n",
    "\n",
    "Fortunately, for most of established machine learning algorithms, such as Linear Regression, we do not need to implmenet the optimization ourselves. Sklearn, as a general Python Machine Learning library, offers implementations of a wide range of commonly used models. All you need to do is to import the appropriate modules from sklearn, and call `.fit(X, y)` to fit (train/optmize) your chosen model on the training data $X$ and its associated labels $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.120548Z",
     "start_time": "2019-06-15T21:31:02.027Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Pratice 4.2. Inspect the coefficients optimized by sklearn\n",
    "\n",
    "In Pratice 4.1, you may have used the closed-form solution to find the optimal set of cofficients $\\theta^*$. In this part, you will need to find their counterpart optimized by sklearn.\n",
    "\n",
    "Useful resources: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html (hint: Look at the examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.121776Z",
     "start_time": "2019-06-15T21:31:02.029Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: find out the coefficients and intercept optimized by the sklearn LinearRegression object `regressor` above.\n",
    "# and compare them with \\theta^* you got from Practice 4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate linear regressor\n",
    "\n",
    "Since we are now done with our **phase 1: training time** (i.e., we have finished model optimization on our training data), we move on to our **phase 2: validation time**, where we need to evaluate how good our trained model is on a validation set. This validation set is the `X_test`, and `y_test` we got from the **train-test split of the dataset** step above.\n",
    "\n",
    "In order to evaluate the model quality on `X_test`, we need to first use our trained model `regressor` to predict the outcome on `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.122902Z",
     "start_time": "2019-06-15T21:31:02.032Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.124202Z",
     "start_time": "2019-06-15T21:31:02.034Z"
    }
   },
   "outputs": [],
   "source": [
    "# you can inspect what `y_pred` is. It is a 1-d vector (basically a list) of float numbers.\n",
    "# and visually compare each individual prediction with the ground truth in `y_test`.\n",
    "for i, yi in enumerate(y_pred):\n",
    "    print(f'y_pred: {yi}\\ty_truth: {y_test[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can choose a set of evaluation metrics appropriate to our current task, i.e., regression, to compare our predicted values `y_pred` against the ground-truth `y_test`.\n",
    "\n",
    "Sklearn, as a general Python Machine Learning package, offers common evaluation metrics out of the box. In class, we introduced **r2**, **mean absolute error**, and **mean squared error**. All of them can be found in `sklearn.metrics` module. Useful resources: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.125379Z",
     "start_time": "2019-06-15T21:31:02.036Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_pred, y_test):\n",
    "    r2 = r2_score(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    print(f'r2: {r2}')\n",
    "    print(f'mse: {mse}')\n",
    "    print(f'mae: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.126680Z",
     "start_time": "2019-06-15T21:31:02.038Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear regressor with standardized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it is a good idea to perform certain preprocessing steps, such as feature standardization and normalization, imputation, outlier removal, on your training data. Especially when you are using models which are very sensitive to outliers and individual feature magnitude, such as Linear Regression models. For other more robust models, these steps may make little difference but rarely harm. Therefore, it is generally recommended to perform these preprocessing steps, unless proved otherwise.\n",
    "\n",
    "sklearn's `preprocessing` module provides a variety of common preprocessing steps.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.127963Z",
     "start_time": "2019-06-15T21:31:02.040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use StandardScaler to standardize our training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit this StandardScaler on our training data, i.e., estimating the mean and variance base don our training data\n",
    "X_train = scaler.fit(X_train)\n",
    "\n",
    "# use the fitted StandardScaler object \"scaler\" to transform X_train, i.e., to actually performing standardization on X_train\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "### the above two step can be combined into one step (which is more commonly used than the two steps approach)\n",
    "### X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Pratice 4.3. Fit LinearRegression model on this standardized training set now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.129391Z",
     "start_time": "2019-06-15T21:31:02.044Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: fit regressor on the standardized training data `X_train` now\n",
    "# print out the new coefficients and intercept\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the new model with standardized features\n",
    "\n",
    "To evaluate our new model, similarly to what we have done in the **Evaluate linear regressor** step, we need to first produce predictions of `X_test` using our newly trained model.\n",
    "\n",
    "**EXTREMELY IMPORTANT (READ CAREFULLY):** If your applied any preprocessing steps in training time, you need to perform the same steps in prediction time as well!! Remember in the **Building Blocks of Machine Learning Applications** diagram, in phase 2, we always apply exactly the same set of feature extraction steps to convert raw data into matrices before fed into our trained model. **However, at training time, you may have used X_train = `scaler.fit_transform(X_train)` to transform your training data; at prediction time, NEVER use `.fit()` again!** Calling `.fit()` again on X_test would likely to produce inconsistent preprocessing result and make your trained model invalid or unusable.\n",
    "\n",
    "Instead, we simply use `X_test=scaler.transform(X_test)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.130468Z",
     "start_time": "2019-06-15T21:31:02.046Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ Pratice 4.4. Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T21:31:03.131438Z",
     "start_time": "2019-06-15T21:31:02.049Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: get the evaluation result on your new model by the same set of evaluation metrics: r2_score, mse, and mae\n",
    "# Is the new performance better or worse than before?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
