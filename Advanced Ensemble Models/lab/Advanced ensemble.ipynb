{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - Assignment Week 7 </h3>\n",
    "<h1 align='center'> Advanced Ensemble Methods\n",
    " </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "We are going to use the same dataset as last week, to perform advanced ensemble methods in this assignment. To recap, this is the competition overview: https://www.kaggle.com/c/home-credit-default-risk#description.\n",
    "The task is to predict whether each credit applicant is going to have payment difficulty or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-work: \n",
    "0. Randomly sample a good amount of rows from the raw data for this task\n",
    "1. Perform data exploration and some proper data pre-possessing.\n",
    "2. Randomly mask **20%, 10% and 5%** in features `AMT_INCOME_TOTAL`, `AMT_CREDIT`, `AMT_ANNUITY` as missing values respectively.\n",
    "3. Split the data into **70%** of training and **30%** of testing. Remember to specify the random seed for the sake of reproducibility.\n",
    "\n",
    "# Model building, validation and testing\n",
    "1. Impute the *missing* values by simple average from the training data. Fit a `RandomForestClassifier` using `RandomizedSearch` to tune some hyper-parameters (which ones you choose to tune and why?). Remember to specify the random seed for the `RandomizedSearch`. Choose the AUC as the `scoring` metric. Carefully choose the hyperparameter `class_weight` to address the imbalanced classfication issue. Print out the feature improtance.\n",
    "2. Impute the *missing* values by `SMOTE` and repeat the same things in step 1.\n",
    "3. Under the optimal model got from step 1, plot the `Out-of-bag` (OOB) error (`oob_score_`) and the error on the testing dataset with X-axis being the number of tress grown.\n",
    "4. (Bonus) Implement the `Proximities-weighted` method to impute missing values and repeat the same things in step 1. Compare the model performance on the testing dataset. \n",
    "5. Build a `GradientBoostingClassifier` model following the same procedures as described in step 1.\n",
    "6. Build a `XGBoost` model following the same procedures as described in step 1.\n",
    "7. Impute the *missing* values by simple average from the training data. Build a standard stacking model where we choose `SVM`, `KNN`, `Decision Trees`, `Logistic Regression` as the base learners; `XGBoost` as the meta-learner.\n",
    "\n",
    "*Final thoughts:*\n",
    "Comparing the testing metrics in RF model, GB model, XGBoost and stacking model, which one would you choose in production, why?\n",
    "\n",
    "> Reference: \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "- https://xgboost.readthedocs.io/en/latest/index.html\n",
    "- https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
