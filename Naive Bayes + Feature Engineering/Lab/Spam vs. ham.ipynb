{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - In-class Lab Week 3 </h3>\n",
    "<h1 align='center'> Naive Bayes: Spam vs. Ham </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Used:**\n",
    "\n",
    "- Pandas\n",
    "- NumPy\n",
    "- Sklearn\n",
    "- [NLTK](https://www.nltk.org/): a convenient Python library for natural language processing.\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install NLTK**\n",
    "\n",
    "- Install the NLTK package by running this in your terminal: `pip install nltk`\n",
    "- Download relevant NTLK data by running this in your terminal: `python -m nltk.downloader stopwords`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Dataset\n",
    "\n",
    "In this exercise, we will be using the famous [email spam classification dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset#spam.csv) `spam.csv`.\n",
    "\n",
    "This CSV file contains two columns only: the `label` that you wish to predict, and the actual message.\n",
    "\n",
    "There are two possible labels:\n",
    "1. `spam`: this message is a spam.\n",
    "2. `ham`: this message is not a spam.\n",
    "\n",
    "We will be using `NaiveBayes` to build this message spam classifier.\n",
    "\n",
    "In addition to practicing this new model, we will be experimenting with various techniques to perform text feature engineering on this dataset.\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ Separate labels and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "X = df['message'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Omega$ (Practice) Split data into 80% training and 20% testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "\n",
    "Naive Bayes classifier is a generative classifier:\n",
    "- We build a model of $P(x│y)$, which can be used to generate new samples for a given class $y$.\n",
    "- We apply Bayes rule to get $P(y│x)$.\n",
    "- The decision rule is therefore:\n",
    "\n",
    "<center>\n",
    "    \\begin{align}\n",
    "    \\widehat{y} & =arg\\max_t P(y=t│x) \\\\\n",
    "                & =arg\\max_t \\dfrac{P(y=t)P(x│y=t)}{P(x)} \\\\\n",
    "                & =arg\\max_t P(y=t)P(x│y=t),\n",
    "    \\end{align}\n",
    "</center>\n",
    "\n",
    "  where $t\\in \\{\\textit{\"spam\"}, \\textit{\"ham\"}\\}$.\n",
    "\n",
    "\n",
    "- Assuming conditional independence among features:\n",
    "<center>\n",
    "    $P(x│y=t)=\\Pi_{j=1}^pP(x_j│y=t)$\n",
    "</center>\n",
    "\n",
    "In Naive Bayes, there is no optimization via gradient descent; rather, we need to estimate the following probabilities:\n",
    "\n",
    "1. **Class priors**: $P(y=t)$\n",
    "2. **Class-conditional features**: $P(x_j│y=t)$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Omega$ (Practice) Estimating class priors: $P(y=t)$\n",
    "\n",
    "\n",
    "Similar to the models we learned previously, all the parameter fitting or probability estimation tasks must be **conducted on the training data only**.\n",
    "\n",
    "Basically, to estimate class priors $P(y=t)$, all we need to do is to find out the natural (prior) distribution of the two classes `spam` and `ham` in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: collect the count of each label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: convert raw count into probabilities for each class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ Estimating conditional probabilities of features: $P(x_j│y=t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features $x_j$\n",
    "\n",
    "The most straightforward definition of each feature $x_j$ is by defining it as each individual word in the email. \n",
    "\n",
    "For example, $P(\\textit{\"you\"}│y=\\textit{\"spam\"})$ represents the probability of seeing the word \"**_you_**\" **given the email is a spam message**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split emails into words (tokenization)\n",
    "\n",
    "For text-type data, we often needs to split the entire text into words (**tokens**), so we can apply techniques such as **bag-of-words** models. This can be easily done using NLTK's `sentence_tokenize` and `word_tokenize` functions.\n",
    "\n",
    "> Question: can we just split the text by space to get all the words?\n",
    "\n",
    "> Answer: it works in most cases, but would fail for corner cases such as punctuations. For example, the sentence `It is a nice day.` should be tokenized into `[\"It\", \"is\", \"a\", \"nice\", \"day\", \".\"]` -- notice how the period `.` is a token on its own. If we split this sentence by white spaces, we would end up with `[\"It\", \"is\", \"a\", \"nice\", \"day.\"]` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define preprocessing function: message -> sentences -> words\n",
    "import nltk\n",
    "def preprocess(message):\n",
    "    sentences = nltk.sent_tokenize(message) # split the email message into sentences\n",
    "    \n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = nltk.word_tokenize(sentence) # split each sentence into a list of words\n",
    "        tokens.extend([token.lower() for token in sentence_tokens]) # convert each word to lower cases\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: for each email, we apply preprocess()\n",
    "words_train = [preprocess(message) for message in msg_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: check the tokenization result\n",
    "for i, words in enumerate(words_train):\n",
    "    print(f'{msg_train[i]} -> {words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ (Practice) Calculate $P(x_j│y=t)$\n",
    "\n",
    "Once we define $x_j$ as each individual word, how can we calculate the conditional probability $P(x_j│y=t)$, which represents the likelihood of seeing the word $x_j$ appears in a message of class $t$ (i.e., $t$=\"spam\" or \"ham\"). The most naive way to calculate this likelihood $P(x_j│y=t)$ is by using the raw frequency:\n",
    "\n",
    "<center>\n",
    "$P(x_j│y=t)=\\dfrac{count(x_j, t)}{\\Sigma_{k=1}^V{count(x_k, t)}}$\n",
    "</center>\n",
    "\n",
    "For example, $P(\\textit{\"you\"}│y=\\textit{\"spam\"})=\\dfrac{count(\\textit{\"you\"}, \\textit{\"spam\"})}{\\Sigma_{k=1}^V{count(x_k, \\textit{\"spam\"})}}$\n",
    "\n",
    "- $count(\\textit{\"you\"}│y=\\textit{\"spam\"})$ is the number of times the **word \"_you_\" occurs in all _spam_ emails.**\n",
    "- $\\Sigma_{k=1}^V{count(x_k, \\textit{\"spam\"})}$ is the **total number of times** each word in the vocabulary occurs in all _spam_ emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_p_xy(label2cnt, words_train, y_train):\n",
    "    # Step 1: calculate the raw word counts for each class, and stores them in `count_xy`\n",
    "    # for example, `count_xy` would look seomthing like (the actual numbers would be different):\n",
    "    # {\n",
    "    #    \"spam\": {\"the\": 100, \"and\": 99, \"you\": 64, ...},\n",
    "    #    \"ham\": {\"the\": 200, \"and\": 70, \"you\": 12, ...}\n",
    "    # }\n",
    "    # which means, in `spam` messages, the word \"the\" appears 100 times, and the word \"and\" appears 99 times, and so on.\n",
    "    # In `ham` messages, the word \"the\" appears 200 times, and the word \"and\" appears 70 times, and so on.\n",
    "    # Note: this `count_xy` should be a dictionary of dictionaries, where the top-level key is the class, \"spam\" or \"ham\",\n",
    "    # and each key maps to a dictionary with word frequencies, calculated from messages belonging to that class.    \n",
    "    # TODO\n",
    "    count_xy = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Step 2: normalize the raw frequencies by the denomiator in the formula above.\n",
    "    # i.e., normalize the raw count in `count_xy` by the total number of words in the messages of this class \n",
    "    # After this step, the values in `count_xy` should be all floats, and thus represents valid probabilities.\n",
    "    # TODO\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return count_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_xy = estimate_p_xy(label2cnt=label2cnt, words_train=words_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ (Practice) Print out the top 20 most frequent words for each class\n",
    "\n",
    "Use your calculated `count_xy` above, print out the top 20 most frequent words for each class.\n",
    "\n",
    "What do you see in these lists? Do the top words look meaningful, and thus would be helpful for differentiating different message classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the following probabilities:\n",
    "1. The prior probabilties of the classes, $P(y=t)$, calculated in step 6;\n",
    "2. The conditional likelihoods, $P(x_j|y=t)$, calculated in step 7\n",
    "\n",
    "We can now generate predictions for a given new message -- whether this is a spam or ham message. The decision rule for predicting a new message instance, vectorized as $x$ is a follows:\n",
    "\n",
    "<center>\n",
    "    \\begin{align}\n",
    "    \\widehat{y} & =arg\\max_t P(y=t│x) \\\\\n",
    "                & =arg\\max_t \\dfrac{P(y=t)P(x│y=t)}{P(x)} \\\\\n",
    "                & =arg\\max_t P(y=t)P(x│y=t) \\\\\n",
    "                & =arg\\max_t P(y=t)\\prod_j P(x_j│y=t),\n",
    "    \\end{align}\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ Use the decision above to geneate the prediction for each test instance\n",
    "\n",
    "As demonstrated in the decision rule formula, we simply need to calculate $P(y=t|x)$, for $t \\in \\{spam, ham\\}$ by replacing the probabilities $P(y=t)$ and $P(x_j|y=t)$ with the probabilities we calculated from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam_or_ham(words_test, priors, count_xy):\n",
    "    cls_probs = dict() # keeps track P(y=t|x)\n",
    "    for label, label_prior in priors.items():\n",
    "        prob = 1.0\n",
    "        for word in words_test:\n",
    "            p_xy = count_xy[label][word]\n",
    "            prob *= p_xy\n",
    "        \n",
    "        cls_probs[label] = prob * label_prior\n",
    "        # note: cls_probs[label] does not represent valid probabilities, \n",
    "        # as we take out the normalizaton probability $P(x)$ in the calculation\n",
    "    \n",
    "    # the class label that maximzes `cls_probs` is our prediction\n",
    "    best_label, best_prob = max(cls_probs.items(), key=lambda x:x[1], reverse=True)[0]\n",
    "    \n",
    "    return best_label, best_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "probs = []\n",
    "for message in msg_test:\n",
    "    words_test = preprocess(message) # use the same preprocessing on the test email message\n",
    "    predicted_label, label_prob = predict_spam_or_ham(words_test, priors, count_xy)\n",
    "    predictions.append(predicted_label)\n",
    "    probs.append(label_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$ (Pratice) Evaluate mode performance\n",
    "\n",
    "Once we got our predictions on the test set, we can conduct performance evaluation to get an idea of how good this Naive Bayes implementation is.\n",
    "\n",
    "Hint: use sklearn's `classification_report` and `accuracy_score` as we saw in last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_prediction(predictions, y_test):\n",
    "    # TODO: print out classification report and the overall accuracy score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions=predictions, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the performance you have right now is decent? If not, let's move on to the improvement steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Delta$ Improvements\n",
    "\n",
    "We got a working Naive Bayes model, but it is not doing so great right now.\n",
    "\n",
    "There are couple problems with using the raw frequence to represent $P(x_j│y=t)$:\n",
    "\n",
    "1. Any unseen words in the dataset would have $P(x_j│y=t)=0$, and therefore $P(x│y=t)=\\Pi_{j=1}^pP(x_j│y=t)=0$, which is problematic. We call these words in the test set which are not observed in training set as `out-of-vocabulary` (OOV) words.\n",
    "  > Hint: inspect the `predictions` and `probs` you got from Step 6.2 and see how some of the `probs` are zero.\n",
    "\n",
    "2. As we saw in the class, we normally would want to remove stopwords from the text as those words bear little information. For example, as we saw in 5.3, the top 20 words in either class, _\"spam\"_ or _\"ham\"_, are pretty much all stopwords and punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ Improvement 1: Smoothing to tackle zero probability $P(x_j│y=t)=0$\n",
    "\n",
    "\n",
    "An easy technique for smoothing is to assume any word has at least one occurrence:\n",
    "\n",
    "\n",
    "<center>\n",
    "$P(x_j│y=t)=\\dfrac{count(x_j, t)+1}{\\Sigma_{k=1}^V{count(x_k, t)}+|V|}$\n",
    "</center>\n",
    "\n",
    "Where $V$ is the set of distinct words in the training data. We usually call $V$ the vocabulary of the training data. ANd $|V|$ is the size of this vocabulary, i.e., the number of distinct words in the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ (Practice)  Improve `estimate_p_xy` by applying the \"plus one\" smoothing\n",
    "\n",
    "Now let's improve how we calculate `count_xy` in Step 6 by applying the \"plus one\" smoothing in the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "# Redefine a smoothed probability estimation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def estimate_p_xy_smoothed(label2cnt, words_train, y_train, bias, V):\n",
    "    # Step 1: calculate the raw word counts for each class, and stores them in `count_xy`.\n",
    "    # This should be the same as the Step 1 in the `estimate_p_xy` function in Step 5.2.\n",
    "    # TODO\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Step 2: normalize the raw frequencies using the formula above.\n",
    "    # i.e., we should add 1 to the numerator and the vocabulary size to the denominator.\n",
    "    # After this step, the values in `count_xy` should be all floats, and thus represents valid probabilities.  \n",
    "    # TODO\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return count_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_xy(count_xy, label, word, bias, V):\n",
    "    # if the word is not in our collected `count_xy` (it is an oov word), \n",
    "    # we will return a default value 1/V\n",
    "    return count_xy[label].get(word, bias/V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam_or_ham_smoothed(words_test, priors, count_xy, bias, V):\n",
    "    cls_probs = dict() # keeps track P(y=t|x)\n",
    "    for label, label_prior in priors.items():\n",
    "        prob = 1.0\n",
    "        for word in words_test:\n",
    "            # Instead of using `count_xy[label][word]` directly, we call this `get_p_xy` function to perform\n",
    "            # smoothing for the words (possibly out of vocabulary) in test instances\n",
    "            p_xy = get_p_xy(count_xy=count_xy, label=label, word=word, bias=bias, V=V)\n",
    "            prob *= p_xy\n",
    "        \n",
    "        cls_probs[label] = prob * label_prior\n",
    "    \n",
    "    best_label, label_prob = sorted(cls_probs.items(), key=lambda x:x[1], reverse=True)[0]\n",
    "    return best_label, label_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ (Practice) Calculate the vocbulary size\n",
    "\n",
    "Implement the `get_vocabulary_size` function below to get the vocabulary size, i.e., the number of distinct words in the **training data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_size(words_train):\n",
    "    # TODO: count the number of distinct words in words_train\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta$ Generate new predictions \n",
    "\n",
    "We can now generate predictions using our improved model. The major difference between this step and Step 6.1 is how we calculate `count_xy` and how we get `best_label` and `label_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = get_vocabulary_size(words_train)\n",
    "\n",
    "count_xy = estimate_p_xy_smoothed(label2cnt=label2cnt, words_train=words_train, y_train=y_train, bias=1, V=V)\n",
    "predictions = []\n",
    "for message in msg_test:\n",
    "    words_test = preprocess(message) # use the same preprocessing procedure on the new test message `msg_test`\n",
    "    best_label, label_prob = predict_spam_or_ham_smoothed(words_test, priors, count_xy, bias=1, V=V)\n",
    "    predictions.append(best_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta$ Evaluate your new model\n",
    "\n",
    "Is it much better now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate your new model by comparing the new set of predictions with y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$ Improvement 2: Removing stopwords and punctuations\n",
    "\n",
    "As introduced eariler, the second improvement we can work on is to remove stopwords and punctuations when we perform feature engineering. This step is generally the best practice for building NLP applications, although its effect sometimes depends on particular tasks. For example, for our spam vs. ham problem, intuitively, massive use of punctuations, especially `!`, in a message might be an indicator of spamming.\n",
    "\n",
    "However, to answer the question of whether a certain feature engineering technique is useful or not, we need to implement it first, and observe how it affects the overall performance.\n",
    "\n",
    "In this practice, We will use NLTK's stopwords set to look up English stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta$ Define the list of exclude words: stopwords \n",
    "\n",
    "As introduced in the lecture, stopwords are those words which generally bear very little meaning, such as `a`, and `the`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### $\\Delta$ Modify the `preprocess` function in Section 7 to exclude stopwords and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define preprocessing function: message -> sentences -> words\n",
    "import nltk\n",
    "def preprocess_stopwords_removed(message, en_stopwords):\n",
    "    sentences = nltk.sent_tokenize(message) # split the email message into sentences\n",
    "    \n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = nltk.word_tokenize(sentence) # split each sentence into a list of words\n",
    "        for token in sentence_tokens:\n",
    "            if token.lower() not in en_stopwords:\n",
    "                tokens.append(token.lower())\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### $\\Omega$ (Practice) Apply the new `preprocess_stopwords_removed` function to `msg_train`\n",
    " \n",
    " Previously, we applied the basic `preprocess` function to get the list of tokens for each training message in `msg_train`. Now let's apply the improved preprocessing function `preprocess_stopwords_removed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply the new preprocess_stopwords_removed function to each message in msg_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Omega$ (Practice) Generate new predictions using the new set of  `words_train` and  `words_test`\n",
    "\n",
    "Hint: this would be a lot similar to the code in Section 7.1.3, but with `preprocess_stopwords_removed` applied to each message in `msg_test` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate new predictions using the new set of  `words_train` and  `words_test`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta$ Evaluate your new model\n",
    "\n",
    "Is it better or similar to the performance we got from applying improvement 1 only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate your new model by comparing the new set of predictions with y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
