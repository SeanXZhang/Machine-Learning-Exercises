{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Applied Machine Learning Course - Assignment Week 6 </h3>\n",
    "<h1 align='center'> Home Credit Default Risk\n",
    " </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> Developed by:</center>\n",
    "<center align=\"left\"> WeCloudData Academy </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In lab, we practiced using `BaggingClassifier` to train an ensemble model. In this assignment, let's train a more sophisticated model (i.e., `AdaBoost`).\n",
    "\n",
    "In this assignment, you are expected to do some parameter tuning fo ryou `AdaBoostClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Read the competition overview at https://www.kaggle.com/c/home-credit-default-risk#description.\n",
    "We are trying to predict whether each credit applicant is going to have payment difficulty or not.\n",
    "\n",
    "This is the same dataset we used in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: \n",
    "\n",
    "**Use Pycharm to finish the following**:\n",
    "\n",
    "1. Do proper feature extraction by fitting `DictVectorizer`. Perform any necessary preprocessing (such as handling missing values and scaling/normalization)\n",
    "2. Fit a `AdaBoostClassifier` using `DecisionTrees` (the default one) as base_estimator:\n",
    "   - Reference: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "3. Use `RandomizedSearch` to tune your `AdaBoostClassifier` with the following parameters:\n",
    "   - `n_estimators`\n",
    "   - `learning_rate`\n",
    "   \n",
    "   Reference: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\n",
    "Note: the original dataset is quite large. You can randomly sample a good amount of rows from it for this task.\n",
    "\n",
    "> Note: the distribution of the two classes in the dataset is very skewed. Therefore, it is not wise to use `accuracy` as the scoring metric for your parameter tuning. Pick a more reasonble one from [score metric](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) and set the `scoring` parameter in your `RandomizedSearchCV` object as that metric.\n",
    "\n",
    "4. Report the final performance of your tuned `AdaBoostClassifier` on your validation data. Compare that with the performance obtained using one single classifier only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
